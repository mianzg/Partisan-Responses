{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rostro36/Partisan-Responses/blob/master/QA_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "vmCthZqgCf6N",
    "outputId": "3970851a-dadd-45e8-fc55-98d8d2867d0f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Partisan-Responses-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bTX7NlwGoTeO",
    "outputId": "c4cb5a42-5c06-447d-9cb6-10ed8f0b87e3"
   },
   "outputs": [],
   "source": [
    "# Install libraries if needed\n",
    "#! pip install transformers\n",
    "! pip install allennlp allennlp-models\n",
    "! pip install hnswlib\n",
    "! pip install wandb\n",
    "! pip install neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCuXIdqmE5df"
   },
   "source": [
    "Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541,
     "referenced_widgets": [
      "5b8681875c1347698138ad1b2a09e2d1",
      "2751bafe24b44894bb833fe999da5340",
      "2bd43e78d28045a98ceb967d0b4337b6",
      "669a510edb934f28bcdb0ea02392acb6",
      "342c7f6fce2c4cc9b82b1f35a8491d8d",
      "9023c492bd604382bd1cccadc98b29ff",
      "f2ef546ef6aa428481550f40759cdb62",
      "f695ffdc7c0e4ebea25bcb513481370e",
      "75511bca5243413f98359f75d7348f76",
      "e5fa2ee6d1b74d95a8f47e45e6f1127c",
      "bee1a93330134aea9c829c37acd92c71",
      "e3c0563a908743a9876dc248ffc6af50",
      "ed71e9af8bf54ba3a02b550c8adf2bf9",
      "1bda365c3fd4439480a48e59029f2fad",
      "912897b023ab4415a030b1855ad416e5",
      "509f370c94244bbfa328eb411c61c915",
      "9ba430a9d0284c5b813d7df20382e22e",
      "9d01cdcc51af4cc88a1612262439e3a0",
      "c8c647a6651641ba94b2a7e26cfb2cfd",
      "0b3589c942d24b1eaa285f18510f3e4b",
      "7bda5de624c64a30b5da0141ef83c092",
      "24a7f497e81a485db04fe26ff4ab0677",
      "2f3db6cdd77649a3a1251423de638770",
      "f75e9a057da5426ba80a5b0e99505208"
     ]
    },
    "colab_type": "code",
    "id": "Zunm7WJ8EC-7",
    "outputId": "f7f76ff9-4fbe-48f6-f343-5794711e8511"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from itertools import islice\n",
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from Search import Search\n",
    "from Answer import Answer\n",
    "from Speech import Speech\n",
    "from KnowledgeGraph import KnowledgeGraph\n",
    "import neuralcoref\n",
    "import re\n",
    "import gc\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "lyIxP4uSGgzD",
    "outputId": "987425e6-a51c-45fb-fd92-3d6d89de1c73"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CWzSZ_3aE8eu"
   },
   "source": [
    "Load data & search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Axk6n8hEOq-"
   },
   "outputs": [],
   "source": [
    "# Last 14 Congresses\n",
    "file_name = 'search_dataset_small.pkl'\n",
    "speeches = pd.read_pickle(file_name)\n",
    "speeches.head()\n",
    "speeches = speeches.loc[:1000,:]\n",
    "#search = Search(speeches=speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "pCSvIO-5Erlg",
    "outputId": "0cb5af2b-05ac-4108-ce01-bce0fe92df59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_R</th>\n",
       "      <th>answer_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should abortion be illegal?</td>\n",
       "      <td>Mr. President, my amendment simply remedies a ...</td>\n",
       "      <td>Will the Senator yield to answer a question so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you believe about tax increases?</td>\n",
       "      <td>Mr. Speaker, I note that the Speaker of the Ho...</td>\n",
       "      <td>Do you remember the other bill that he signed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Should same-sex marriage be legal?</td>\n",
       "      <td>Then I will submit all this for the RECORD and...</td>\n",
       "      <td>Mr. Speaker, I yield myself such time as I may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is climate change real?</td>\n",
       "      <td>Mr. President, this amendment addresses the la...</td>\n",
       "      <td>Mr. Speaker, I thank the distinguished gentlem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Should immigrants be allowed to obtain citizen...</td>\n",
       "      <td>Mr. Chairman, as a strong advocate of immigrat...</td>\n",
       "      <td>Mr. President, I am pleased to introduce legis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ...                                           answer_D\n",
       "0                        Should abortion be illegal?  ...  Will the Senator yield to answer a question so...\n",
       "1           What do you believe about tax increases?  ...  Do you remember the other bill that he signed ...\n",
       "2                 Should same-sex marriage be legal?  ...  Mr. Speaker, I yield myself such time as I may...\n",
       "3                            Is climate change real?  ...  Mr. Speaker, I thank the distinguished gentlem...\n",
       "4  Should immigrants be allowed to obtain citizen...  ...  Mr. President, I am pleased to introduce legis...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = pickle.load(open(\"search_results.pkl\", \"rb\"))\n",
    "search.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TToRwu9FD9-"
   },
   "outputs": [],
   "source": [
    "# Manual Questions (not from corpus)\n",
    "questions = [\"Should abortion be illegal?\",\n",
    "             \"What do you believe about tax increases?\",\n",
    "             \"Should same-sex marriage be legal?\",\n",
    "             \"Is climate change real?\",\n",
    "             \"Should immigrants be allowed to obtain citizenship?\",\n",
    "             \"Who should be given voting rights?\",\n",
    "             \"Should we have higher taxes for higher incomes?\",\n",
    "             \"Should we allow death penalty?\",\n",
    "             \"Should we have universal healthcare?\",\n",
    "             \"Do government regulations hinder free market capitalism?\",\n",
    "             \"What do you think about the current president?\",\n",
    "             \"Should we reduce national debt?\",\n",
    "             \"Should we increase spending on healthcare?\",\n",
    "             \"Should we increase spending on education?\",\n",
    "             \"Should every American have equal opportunities regardless of sex, age and race?\",\n",
    "             \"Should be introduce more gun control measures?\",\n",
    "             \"What do you think about the current president?\",\n",
    "             \"Should Americans be free?\",\n",
    "             \"What party do you support?\",\n",
    "             \"What is the biggest threat to America?\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejzc2QxBKbE4"
   },
   "source": [
    "Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5q8aFQfHmfSF"
   },
   "outputs": [],
   "source": [
    "#from KnowledgeGraph import KnowledgeGraph\n",
    "knowledgeGraphs=dict()\n",
    "for question in questions:\n",
    "  knowledgeGraphs[question]=KnowledgeGraph(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y34yH5-bVfR0"
   },
   "outputs": [],
   "source": [
    "identifier='coref'\n",
    "checkpoint=12\n",
    "#verb_list_file = \"verb_list\"+identifier+str(checkpoint)+\".pickle\"\n",
    "verb_dict = pickle.load(open(\"verb_dict.pickle\", \"rb\"))\n",
    "verb_list = None #pickle.load(verb_list_file)\n",
    "graphWriterData=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3qYZioDUlpb"
   },
   "outputs": [],
   "source": [
    "def parse_entry(question,answer,verb_dict,verb_list):\n",
    "    result=dict()\n",
    "    result['question']=' '.join([token.text for token in utils.sp(question)])\n",
    "    phrase_corpus, triplet_id, parsed_text,parsed=Answer(answer).create_test(verb_dict,verb_list)\n",
    "    result['corpus']=' ; '.join(phrase_corpus)\n",
    "    result['tags']=' '.join(['<phrase>']*len(phrase_corpus))\n",
    "    result['triplet_id']=' ; '.join([re.sub('\\,','',str(x))[1:-1] for x in triplet_id])\n",
    "    result['parsed_text']=parsed_text\n",
    "    result['parsed']=' '.join([str(x) for x in parsed])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qw2bej-rGIoK"
   },
   "source": [
    "Generate answers to question with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLeDBLVxKuZS"
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UhCPNvFGN3xp",
    "outputId": "2bead479-2717-466a-bd9a-61d776708532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Should abortion be illegal?\n",
      "GPT-2 generation: \n",
      "Should abortion be illegal?\n",
      "\n",
      "The Supreme Court has ruled that abortion is illegal under the Fourteenth Amendment. The Supreme Court has ruled that abortion is illegal under the Fourteenth Amendment.\n",
      "\n",
      "The Supreme Court has ruled that abortion is illegal under the Fourteenth Amendment.\n",
      "\n",
      "The Supreme Court has ruled that abortion is illegal under the Fourteenth Amendment.\n",
      "\n",
      "The Supreme Court has ruled that abortion is illegal under the Fourteenth Amendment.\n",
      "\n",
      "The Supreme Court has ruled that abortion is illegal under the Fourteenth Amendment.\n",
      "Question: What do you believe about tax increases?\n",
      "GPT-2 generation: \n",
      "What do you believe about tax increases?\n",
      "\n",
      "I think that the tax increases are going to be very good for the economy. I think that the tax increases are going to be very good for the middle class. I think that the middle class is going to be very happy. I think that the middle class is going to be very happy.\n",
      "\n",
      "I think that the middle class is going to be very happy. I think that the middle class is going to be very happy.\n",
      "\n",
      "I think that the middle class is going to\n",
      "Question: Should same-sex marriage be legal?\n",
      "GPT-2 generation: \n",
      "Should same-sex marriage be legal?\n",
      "\n",
      "The Supreme Court has ruled that same-sex marriage is legal in the United States.\n",
      "\n",
      "The Supreme Court ruled that same-sex marriage is legal in the United States.\n",
      "\n",
      "The Supreme Court ruled that same-sex marriage is legal in the United States.\n",
      "\n",
      "The Supreme Court ruled that same-sex marriage is legal in the United States.\n",
      "\n",
      "The Supreme Court ruled that same-sex marriage is legal in the United States.\n",
      "\n",
      "The Supreme Court ruled that same-\n",
      "Question: Is climate change real?\n",
      "GPT-2 generation: \n",
      "Is climate change real?\n",
      "\n",
      "The answer is no.\n",
      "\n",
      "The IPCC's latest report, released on Tuesday, says that global warming is \"likely to continue to increase over the next century.\"\n",
      "\n",
      "The report, which is based on a series of studies, says that the average temperature increase over the past century is about 1.5 degrees Celsius (3.6 degrees Fahrenheit) higher than the average for the last century.\n",
      "\n",
      "The report also says that the average temperature increase over the past century is about 1\n",
      "Question: Should immigrants be allowed to obtain citizenship?\n",
      "GPT-2 generation: \n",
      "Should immigrants be allowed to obtain citizenship?\n",
      "\n",
      "The answer is yes.\n",
      "\n",
      "The U.S. Supreme Court has ruled that the right to vote is not a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to vote is not a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to vote is not a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to vote is not a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to vote is not a fundamental right\n",
      "Question: Who should be given voting rights?\n",
      "GPT-2 generation: \n",
      "Who should be given voting rights?\n",
      "\n",
      "The Supreme Court has ruled that the right to vote is not a fundamental right. The right to vote is not a right to be a citizen of the United States. It is a right to be a citizen of the United States.\n",
      "\n",
      "The right to vote is not a right to be a citizen of the United States. It is a right to be a citizen of the United States.\n",
      "\n",
      "The right to vote is not a right to be a citizen of the United States. It\n",
      "Question: Should we have higher taxes for higher incomes?\n",
      "GPT-2 generation: \n",
      "Should we have higher taxes for higher incomes?\n",
      "\n",
      "The answer is yes.\n",
      "\n",
      "The Tax Policy Center, a nonpartisan think tank, has found that the tax rate on the top 1 percent of earners has increased by more than 10 percentage points since the 1970s.\n",
      "\n",
      "The Tax Policy Center's analysis of the tax code shows that the top 1 percent of earners have paid more in taxes than the bottom 90 percent of Americans.\n",
      "\n",
      "The Tax Policy Center's analysis of the tax code shows that the top 1 percent of earners have paid\n",
      "Question: Should we allow death penalty?\n",
      "GPT-2 generation: \n",
      "Should we allow death penalty?\n",
      "\n",
      "The Supreme Court has ruled that the death penalty is unconstitutional. The Supreme Court has ruled that the death penalty is unconstitutional.\n",
      "\n",
      "The Supreme Court has ruled that the death penalty is unconstitutional.\n",
      "\n",
      "The Supreme Court has ruled that the death penalty is unconstitutional.\n",
      "\n",
      "The Supreme Court has ruled that the death penalty is unconstitutional.\n",
      "\n",
      "The Supreme Court has ruled that the death penalty is unconstitutional.\n",
      "\n",
      "The Supreme Court has ruled that the death penalty is unconstitutional.\n",
      "\n",
      "The Supreme\n",
      "Question: Should we have universal healthcare?\n",
      "GPT-2 generation: \n",
      "Should we have universal healthcare?\n",
      "\n",
      "The answer is yes.\n",
      "\n",
      "The Affordable Care Act (ACA) is a law that allows Americans to buy insurance through the federal government. The ACA is a law that allows Americans to buy insurance through the federal government.\n",
      "\n",
      "The ACA is a law that allows Americans to buy insurance through the federal government.\n",
      "\n",
      "The ACA is a law that allows Americans to buy insurance through the federal government.\n",
      "\n",
      "The ACA is a law that allows Americans to buy insurance through the federal government.\n",
      "Question: Do government regulations hinder free market capitalism?\n",
      "GPT-2 generation: \n",
      "Do government regulations hinder free market capitalism?\n",
      "\n",
      "The answer is yes.\n",
      "\n",
      "The government regulates the free market, but it does not regulate the free market.\n",
      "\n",
      "The government regulates the free market, but it does not regulate the free market.\n",
      "\n",
      "The government regulates the free market, but it does not regulate the free market.\n",
      "\n",
      "The government regulates the free market, but it does not regulate the free market.\n",
      "\n",
      "The government regulates the free market, but it does not regulate the free market.\n",
      "\n",
      "The\n",
      "Question: What do you think about the current president?\n",
      "GPT-2 generation: \n",
      "What do you think about the current president?\n",
      "\n",
      "I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president\n",
      "Question: Should we reduce national debt?\n",
      "GPT-2 generation: \n",
      "Should we reduce national debt?\n",
      "\n",
      "The answer is no. The debt ceiling is a temporary measure that will not be lifted until the next Congress passes a budget resolution. The debt ceiling is a temporary measure that will not be lifted until the next Congress passes a budget resolution.\n",
      "\n",
      "The debt ceiling is a temporary measure that will not be lifted until the next Congress passes a budget resolution.\n",
      "\n",
      "The debt ceiling is a temporary measure that will not be lifted until the next Congress passes a budget resolution.\n",
      "\n",
      "The debt ceiling\n",
      "Question: Should we increase spending on healthcare?\n",
      "GPT-2 generation: \n",
      "Should we increase spending on healthcare?\n",
      "\n",
      "The answer is no.\n",
      "\n",
      "The government has already announced that it will increase spending on healthcare by $1.5 billion over the next five years.\n",
      "\n",
      "The government has also announced that it will increase spending on health care by $1.5 billion over the next five years.\n",
      "\n",
      "The government has already announced that it will increase spending on healthcare by $1.5 billion over the next five years.\n",
      "\n",
      "The government has already announced that it will increase spending on healthcare\n",
      "Question: Should we increase spending on education?\n",
      "GPT-2 generation: \n",
      "Should we increase spending on education?\n",
      "\n",
      "The answer is no.\n",
      "\n",
      "The government has spent $1.5 billion on education since 2009, and the government has spent $1.5 billion on education since 2010.\n",
      "\n",
      "The government has spent $1.5 billion on education since 2009, and the government has spent $1.5 billion on education since 2010.\n",
      "\n",
      "The government has spent $1.5 billion on education since 2009, and the government has spent $1.5 billion on education since 2010.\n",
      "Question: Should every American have equal opportunities regardless of sex, age and race?\n",
      "GPT-2 generation: \n",
      "Should every American have equal opportunities regardless of sex, age and race?\n",
      "\n",
      "The answer is yes.\n",
      "\n",
      "The Supreme Court has ruled that the right to equal access to abortion is a fundamental right. The Court has also ruled that the right to abortion is a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to abortion is a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to abortion is a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled that the right to abortion is a fundamental right.\n",
      "\n",
      "The Supreme Court has ruled\n",
      "Question: Should be introduce more gun control measures?\n",
      "GPT-2 generation: \n",
      "Should be introduce more gun control measures?\n",
      "\n",
      "The NRA has been pushing for more gun control measures since the Newtown, Conn., school shooting.\n",
      "\n",
      "The group has been pushing for more gun control measures since the Newtown, Conn., school shooting.\n",
      "\n",
      "The group has been pushing for more gun control measures since the Newtown, Conn., school shooting.\n",
      "\n",
      "The group has been pushing for more gun control measures since the Newtown, Conn., school shooting.\n",
      "\n",
      "The group has been pushing for more gun control measures since the Newtown,\n",
      "Question: What do you think about the current president?\n",
      "GPT-2 generation: \n",
      "What do you think about the current president?\n",
      "\n",
      "I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president. I think he's a very good president\n",
      "Question: Should Americans be free?\n",
      "GPT-2 generation: \n",
      "Should Americans be free?\n",
      "\n",
      "The answer is no.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "The American people are free to choose their own government.\n",
      "\n",
      "\n",
      "Question: What party do you support?\n",
      "GPT-2 generation: \n",
      "What party do you support?\n",
      "\n",
      "I'm a Democrat. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a Republican. I'm a\n",
      "Question: What is the biggest threat to America?\n",
      "GPT-2 generation: \n",
      "What is the biggest threat to America?\n",
      "\n",
      "The biggest threat to America is the threat of terrorism. The biggest threat to America is the threat of terrorism.\n",
      "\n",
      "The biggest threat to America is the threat of terrorism. The biggest threat to America is the threat of terrorism.\n",
      "\n",
      "The biggest threat to America is the threat of terrorism. The biggest threat to America is the threat of terrorism.\n",
      "\n",
      "The biggest threat to America is the threat of terrorism. The biggest threat to America is the threat of terrorism.\n",
      "\n",
      "The biggest\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    print(\"Question: {}\".format(question))\n",
    "    print(\"GPT-2 generation: \")\n",
    "    generated = tokenizer.encode(question)\n",
    "    context = torch.tensor([generated])\n",
    "    past = None\n",
    "\n",
    "    for i in range(100):\n",
    "        output, past = model(context, past=past)\n",
    "        token = torch.argmax(output[..., -1, :])\n",
    "\n",
    "        generated += [token.tolist()]\n",
    "        context = token.unsqueeze(0)\n",
    "\n",
    "    sequence = tokenizer.decode(generated)\n",
    "\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiXntHFtPkLd"
   },
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TsACyyYBOA3S",
    "outputId": "3196329e-f686-4234-8c96-1e25766bd456"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(7, 96), match='the criminal penalties for marriage fraud to 5 ye>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"(?<=ARG1: )[\\w\\s\\'\\\",\\.\\:\\$\\-\\(\\)\\*\\/]*(?=])\", '[ARG1: the criminal penalties for marriage fraud to 5 years imprisonment and/or a $ 250.000 fine]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6E_kDe_NKne"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import allennlp_models.structured_prediction\n",
    "# import allennlp_models.coref\n",
    "import nltk\n",
    "import re\n",
    "import utils\n",
    "\n",
    "auxillary_verbs=['can','could','may','might','must','shall','should','will','would'] #https://englishstudyonline.org/auxiliary-verbs/\n",
    "distance_threshold=0.5\n",
    "\n",
    "class Speech:\n",
    "    def __init__(self, speech):\n",
    "        #self.speaker = speech['lastname'] + \" \" + speech['firstname']\n",
    "        self.party = speech['party']\n",
    "        self.content = speech['speech']\n",
    "        \n",
    "    def change_comma(self):\n",
    "        \"\"\"\n",
    "        Replace improper period to comma\n",
    "        \"\"\"\n",
    "        self.content = re.sub(\"\\.(?=\\s[a-z0-9]|\\sI[\\W\\s])\", \",\", self.content)\n",
    "\n",
    "    def _find_triplets(self, openinfo_result):\n",
    "        \"\"\"\n",
    "        Find one or more triplets of each sentence from allennlp OIE results\n",
    "        Param:\n",
    "        ========\n",
    "\n",
    "        Return:\n",
    "        ========\n",
    "        speech_triplets: list, a list of lists of triplet tuples (of a speech)\n",
    "        \"\"\"\n",
    "        arg0 = \"ARG0: \"\n",
    "        arg1 = \"ARG1: \"\n",
    "        modalverbs = [\"can\", \"could\", \"may\", \"might\", \"must\", \"shall\", \"should\", \"will\", \"would\"]\n",
    "        speech_triplet = []\n",
    "        for sentence in openinfo_result:\n",
    "            sent_triplet = []\n",
    "            if sentence is not []:\n",
    "                for d in sentence: # Extract from 'description' result of OIE\n",
    "                    verb = d['verb']\n",
    "                    if verb not in modalverbs:\n",
    "                        subjidx = d['description'].rfind(arg0) \n",
    "                        predidx = d['description'].rfind(arg1)\n",
    "                        if subjidx != -1 and predidx != -1:\n",
    "                            print(d['description'])\n",
    "                            # TODO: * in arg0\n",
    "                            subj = re.search(\"(?<=ARG0: )[\\w\\s\\'\\\",\\.\\:\\$\\-\\(\\)\\*\\/]*(?=])\", d['description']).group(0)\n",
    "                            predicate = re.search(\"(?<=ARG1: )[\\w\\s\\'\\\",\\.\\:\\$\\-\\(\\)\\*\\/]*(?=])\", d['description']).group(0)\n",
    "                            sent_triplet.append((subj, verb, predicate))\n",
    "            speech_triplet.append(sent_triplet)\n",
    "        return speech_triplet\n",
    "                \n",
    "    def create_triplet(self):\n",
    "        \"\"\"\n",
    "        Generate (subject, verb, object) triplets of a speech text\n",
    "        Param:\n",
    "        ========\n",
    "        coref_extractor: allennlp coreferece resolution predictor\n",
    "        oi_extractor: allennlp open information extractor\n",
    "\n",
    "        Return:\n",
    "        ========\n",
    "        triplets: list, a list of triplet tuples except the last item being party string\n",
    "        \"\"\"\n",
    "        oie_result=self.create_oieresult()\n",
    "        triplets = self._find_triplets(oie_result)\n",
    "        triplets.append(self.party)\n",
    "        return triplets\n",
    "    \n",
    "    def create_oieresult(self):\n",
    "        coref_content = utils.coref_extractor.coref_resolved(self.content)\n",
    "        sents = nltk.tokenize.sent_tokenize(coref_content)\n",
    "        sents = [{\"sentence\":s} for s in sents] #Format for oie batch predictor\n",
    "        oie_result = utils.open_info_extractor.predict_batch_json(sents)\n",
    "        oie_result = [i['verbs'] for i in oie_result]\n",
    "        return oie_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "id": "swv1FEggFN14",
    "outputId": "816a25bd-caa4-4ce5-d1aa-6a5e1c652a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Should abortion be illegal?\n",
      "Republican Result: Mr. President, my amendment simply remedies a major defect in this bill by ensuring that it does not cover illegal abortions. Why not limit protections of this bill to lawful abortions? I cannot imagine any rationale that could be used to rabut the import of that question. This whole debate shows how extreme this bill is on the proabortion side, I think it would have a lot more support if it was not so extreme, if it did not rush to support illegal abortions and illegal abortionists, to avoid the mere risk of abusive discovery, which is about the only argument they can make. That is a risk every litigant faces, I have been in all kinds of litigation in my lifetime as an attorney. Every case involves the potential abuse of discovery. But to use that as an excuse to not knock out illegal abortions in this bill shows how extreme this bill is. S, 636 very simply protects illegal abortion. It is that simple. Why is it so difficult to want to knock it out? Why is it the Holy Grail of all abortion legislation, that you cannot knock out illegal abortions? I do not know, but that is all that is involved in this amendment. We are making the bill apply only to lawful abortions. That seems to be fair. It seems to be right. It seems to be legal. It seems to make sense. It certainly is a good argument to make. There is not much more I care to say about it, I am prepared to go to a vote, I am prepared to yield back the remainder of my time. Mr. President, I urge all my colleagues to read Debbies letter describing her experience with two abortions. Abortion is one of the, if not the, most serious violations of human rights that one person can inflict on another. It is the deliberate destruction of the offspring of a human beingwhich is without a doubt a human being. But to literally add insult to injury, abortionists are degrading women and endangering the health of the mothers by not adequately informing them of the risks and nature of abortion. Pregnant women, 4.100 of them each day, are procuring abortions, and most of them will not know the basic facts regarding the gestation of their infant, or the type of abortion procedure to be used. It is imperative that S, 2791, my bill requiring informed consent before abortion, be enacted into law in order to protect the emotional and physical health of this Nations women, I ask, in particular, my colleagues from Massachusetts to heed the plea of Debbie, their constituent, and support informed consent before abortion, I ask that Debbies letter be printed in the RECORD. The letter follows: DEAR SENATOR HUMPHREY: My first abortion was Illegal at the age of 18. That didnt stop the doctor from asking me if I wanted an abortion. That was all the counseling I received. It is tragic that the counseling most woman considering abortion receive is so nearsighted. Those who counsel women at abortion clinics are simply interested in rushing scared women and girls into abortions which many will regret later. It may take months, even years, but once the realization of what abortion is and does sets in, women suffer devastating emotional crises and find it very hard to forgive themselves for the role which they had in killing their own children. The tragedy of killing an unborn child by abortion is compounded by the physical harm done by abortion to many women who undergo the procedure, I myself suffered from a very bad infection after my abortion, an infection which spread throughout my body. Other women I know have been forced to have total hysterectomies or simply rendered barren as the result of extensive scarringall because of an abortion to which they never gave informed consent. Abortion is a very dangerous procedure for the mother and child, both physically and psychologically, I, along with many others, became hateful, angry, bitter and resentful after the abortion, I dwelled on the babys due day for years. My next abortion later was legal and the counselling wasnt any better, I wanted to make up for the first baby I killed. In turn I killed this one also. It saddens me to see how tough and \"prochoice\" I became after the second abortion. The first one devastated me and, in order to handle my feelings, I had to become hard and put up a wall, I didnt know how to deal with murder. Can you imagine how it feels years later to see pictures of aborted babies? I thought I would die, seeing what Id done! I am 100% prolife now. Women should be told all the facts about abortion. \"What you dont know can hurt you!\" It kills babies physically and women spiritually. We, the women who have had abortions, know the physical and emotional pain left in abortions wake. It is and has been our struggle to deal with abortions aftermath, now it is our struggle to tell others the truth about abortion. Please help us in this effort. Sincerely. Mr. President, I call upon my colleagues to support S, 272 and S, 273 which require informed consent for women who undergo abortions. Too many women are caught in a psychological trap when they are faced with this important decision. Because of their vulnerable positions, they often choose to have abortions because they are totally unaware of any other alternatives. They also suffer from the emotional and physical scars that often accompany this major surgical procedure. As Debbie Sotirkys of Massachusetts testifies, women should have all the information they need to make the right choice in their abortion decision, I ask that her letter be printed in the REcoRw. The letter follows: DEAR SENATOR HuMPHREY: My first abortion was illegal at the age of 18. That didnt stop the doctor from asking me if I wanted an abortion. That was all the counseling I received. It is tragic that the counseling most women considering abortion receive is so nearsighted. Those who counsel women at abortion clinics are simply interested in rushing scared women and girls into abortions which many will regret later. It may take months, even years, but once the realization of what abortion is and does set in, women suffer devastating emotional crises and find it very hard to forgive themselves for the role which they had in killing their own children. The tragedy of killing an unborn child by abortion is compounded by the physical harm done by abortion to many women who undergo the procedure, I myself suffered from a very bad infection after my abortion, an infection which spread throughout my body. Other women I know have been forced to have total hysterectomies or were simply rendered barren as the result of extensive scarringall because of an abortion to which they never gave informed consent. Abortion is a very dangerous procedure for the mother of the child, both physically and psychologically, I, along with many others, became hateful, angry, bitter, and resentful after the abortion, I dwelled on the babys due date for years. My next abortion a year later was legal and the counseling wasnt any better, I wanted to make up for the first baby I killed. In turn I killed this one also. It saddens me to see how tough and \"prochoice\" I became after the second abortion. The first one devastated me and, in order to handle my feelings, I had to become hard and put up a wall, I didnt know how to deal with murder. Can you imagine how it feels years later to see pictures of aborted babies? I thought I would die, seeing what Id done! I am 100% prolife now. Women should be told all the facts about abortion. \"What you dont know can hurt you!\" It kills babies physically and women spiritually. We, the women who have had abortions, know the physical and emotional pain left in abortions wake. It has been our struggle to deal with abortions aftermath, now it is our struggle to tell others the truth about abortion. Please help us in this effort. Sincerely.\n",
      "Democrat Result: Will the Senator yield to answer a question so when we debate this, I have an understanding? Like I said, this is the first time the Senator from Oklahoma and I have stood nose to nose on this. Does the Senator believe abortion should be illegal? Can I ask the Senator from Oklahoma. Mr. President, does the Senator from Oklahoma feel the same way about tax deductibility of insurance, that we should strike the right of business to deduct insurance if their employees have an offset against FICA? We are basically subsidizing abortions there, if that is the conclusion that he has reached about Federal employees. Mr. President, I ask the Senator from Oklahoma if the same argument that he used against Federal employees being able to use insurance for, not to subsidize abortion, but to purchase a service that continues to be legalit continues to be legal in the United States of America, I do not know, again, whether the Senator from Oklahoma feels that abortion should be made Illegal, but until a majority of Americans feel abortion should be made illegal, it seems to me our employees should have the option to purchase Insurance that contains it, I ask the Senator, does he think tax deductibility should be eliminated against businesses offsetting FICA? That seems to me, as well, that would be a subsidy. Mr. Speaker, 13 years ago today, the right of women to choose abortion in appropriate circumstances was affirmed by the highest court in the land. Abortion is legal, and the overwhelming majority of Americans want to keep it that way. Nevertheless, a vocal minority continues to threaten this fundamental right with a constant barrage of attacks on abortion rights. We must remain ever vigilant against these misguided efforts As a young prosecutor in New York City charged with investigating and prosecuting illegal abortionists, I witnessed firsthand the tragedy of back alley abortions. No one should want to force anyones loved ones back to the hands of the kind of butchers who performed abortions in those days before Roe versus Wade. Millions of women risked permanent disability as a consequence of procedures used in the home or in the underground network of back alley abortionists. Hundreds of women died annually as a result of botched abortions. On this day of remembrance, we must recommit ourselves to maintaining the right to choose. We must support the Supreme Courts refusal to weaken Roe versus Wade. And we must restore full abortion rights to those who suffer unfairly under legislated restrictions. Making abortions illegal didnt prevent abortion. It just made them dangerous and often lethal. A womans right to choose a safe and legal abortion must remain as sacred as any right American citizens enjoy.\n",
      "speech    Mr. President, my amendment simply remedies a ...\n",
      "party                                                     R\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5b6a062836d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_D\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtriplets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSpeech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_triplet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mknowledgeGraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-0cac65837cae>\u001b[0m in \u001b[0;36mcreate_triplet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtriplets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtriplet\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mitem\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mparty\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moie_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_oieresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moie_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-0cac65837cae>\u001b[0m in \u001b[0;36mcreate_oieresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_oieresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mcoref_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoref_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoref_resolved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoref_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Format for oie batch predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/predictors/coref.py\u001b[0m in \u001b[0;36mcoref_resolved\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mspacy_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"clusters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Passing a document with no coreferences returns its original form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/predictors/coref.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mcoreference\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_tokenized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_document\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36mpredict_json\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json_to_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjson_to_labeled_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36mpredict_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInstance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensors\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minto\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_on_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instances\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_output_human_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             instance_separated_output: List[Dict[str, numpy.ndarray]] = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/models/coref.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, spans, span_labels, metadata)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Shape: (batch_size, document_length, embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mtext_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lexical_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_field_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_field_input, num_wrapping_dims, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;31m# If there are multiple tensor arguments, we have to require matching names from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# TokenIndexer.  I don't think there's an easy way around that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mtoken_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken_vectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;31m# To handle some very rare use cases, we allow the return value of the embedder to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/modules/token_embedders/pretrained_transformer_mismatched_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, mask, offsets, wordpiece_mask, type_ids, segment_concat_mask)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Shape: [batch_size, num_wordpieces, embedding_size].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         embeddings = self._matched_embedder(\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordpiece_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_concat_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_concat_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         )\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/modules/token_embedders/pretrained_transformer_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, mask, type_ids, segment_concat_mask)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfold_long_sequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         )\n\u001b[1;32m    729\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.73 GiB total capacity; 11.55 GiB already allocated; 9.88 MiB free; 11.77 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from KnowledgeGraph import KnowledgeGraph\n",
    "for i in range(len(search)):\n",
    "    question = search.iloc[i].question\n",
    "    print(\"Question: {}\".format(question))\n",
    "    answer_R = search.iloc[i].answer_R\n",
    "    print(\"Republican Result: {}\".format(answer_R))\n",
    "    answer_D = search.iloc[i].answer_D\n",
    "    print(\"Democrat Result: {}\".format(answer_D))\n",
    "    \n",
    "    res_R = pd.Series({'speech': answer_R, 'party': 'R'})\n",
    "    res_D = pd.Series({'speech': answer_D, 'party': 'D'})\n",
    "    for res in [res_R, res_D]:\n",
    "        print(res)\n",
    "        triplets=Speech(res).create_triplet()\n",
    "        knowledgeGraphs[question].add_edges(triplets)\n",
    "\n",
    "        #parsed = parse_entry(question,full_result,verb_dict,verb_list)\n",
    "        #graphWriterData.append(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWrp0uKRMKjK"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sD7a_VBJ2aXN"
   },
   "outputs": [],
   "source": [
    "!rm GraphWriter-master/data/preprocessed.test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvXGn7VDvgBl"
   },
   "outputs": [],
   "source": [
    "m=pd.DataFrame(data=graphWriterData)\n",
    "m.to_csv('GraphWriter-master/data/preprocessed.test.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdPdcf-uG3yS"
   },
   "outputs": [],
   "source": [
    "for knowledgeGraph in knowledgeGraphs:\n",
    "  knowledgeGraph.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAEw1xYZz7yk"
   },
   "source": [
    "Text Generation via GraphWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZUQj4TxyJ47"
   },
   "outputs": [],
   "source": [
    "!python GraphWriter-master/generator.py -save=GraphWriter-master/partisan-responses/2.vloss-3.949412.lr-0.05"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "QA_Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b3589c942d24b1eaa285f18510f3e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f75e9a057da5426ba80a5b0e99505208",
      "placeholder": "​",
      "style": "IPY_MODEL_2f3db6cdd77649a3a1251423de638770",
      "value": " 213k/213k [00:08&lt;00:00, 24.4kB/s]"
     }
    },
    "1bda365c3fd4439480a48e59029f2fad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24a7f497e81a485db04fe26ff4ab0677": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2751bafe24b44894bb833fe999da5340": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bd43e78d28045a98ceb967d0b4337b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9023c492bd604382bd1cccadc98b29ff",
      "max": 414,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_342c7f6fce2c4cc9b82b1f35a8491d8d",
      "value": 414
     }
    },
    "2f3db6cdd77649a3a1251423de638770": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "342c7f6fce2c4cc9b82b1f35a8491d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "509f370c94244bbfa328eb411c61c915": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b8681875c1347698138ad1b2a09e2d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bd43e78d28045a98ceb967d0b4337b6",
       "IPY_MODEL_669a510edb934f28bcdb0ea02392acb6"
      ],
      "layout": "IPY_MODEL_2751bafe24b44894bb833fe999da5340"
     }
    },
    "669a510edb934f28bcdb0ea02392acb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f695ffdc7c0e4ebea25bcb513481370e",
      "placeholder": "​",
      "style": "IPY_MODEL_f2ef546ef6aa428481550f40759cdb62",
      "value": " 414/414 [00:15&lt;00:00, 27.1B/s]"
     }
    },
    "75511bca5243413f98359f75d7348f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bee1a93330134aea9c829c37acd92c71",
       "IPY_MODEL_e3c0563a908743a9876dc248ffc6af50"
      ],
      "layout": "IPY_MODEL_e5fa2ee6d1b74d95a8f47e45e6f1127c"
     }
    },
    "7bda5de624c64a30b5da0141ef83c092": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9023c492bd604382bd1cccadc98b29ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "912897b023ab4415a030b1855ad416e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ba430a9d0284c5b813d7df20382e22e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8c647a6651641ba94b2a7e26cfb2cfd",
       "IPY_MODEL_0b3589c942d24b1eaa285f18510f3e4b"
      ],
      "layout": "IPY_MODEL_9d01cdcc51af4cc88a1612262439e3a0"
     }
    },
    "9d01cdcc51af4cc88a1612262439e3a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bee1a93330134aea9c829c37acd92c71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bda365c3fd4439480a48e59029f2fad",
      "max": 665132540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed71e9af8bf54ba3a02b550c8adf2bf9",
      "value": 665132540
     }
    },
    "c8c647a6651641ba94b2a7e26cfb2cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24a7f497e81a485db04fe26ff4ab0677",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7bda5de624c64a30b5da0141ef83c092",
      "value": 213450
     }
    },
    "e3c0563a908743a9876dc248ffc6af50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_509f370c94244bbfa328eb411c61c915",
      "placeholder": "​",
      "style": "IPY_MODEL_912897b023ab4415a030b1855ad416e5",
      "value": " 665M/665M [00:09&lt;00:00, 72.8MB/s]"
     }
    },
    "e5fa2ee6d1b74d95a8f47e45e6f1127c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed71e9af8bf54ba3a02b550c8adf2bf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f2ef546ef6aa428481550f40759cdb62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f695ffdc7c0e4ebea25bcb513481370e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f75e9a057da5426ba80a5b0e99505208": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
