{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rostro36/Partisan-Responses/blob/master/06_GraphWriter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_lpeRFa34jd"
   },
   "source": [
    "Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_JcyaEJb7BY"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Partisan-Responses-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dFdfU1a38rz"
   },
   "source": [
    "Install all requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48m_6NnTcA_R"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install torchtext -U\n",
    "!pip install spacy==2.1.0\n",
    "!pip install neuralcoref allennlp hnswlib allennlp-models\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqzaqs5Q68sV"
   },
   "source": [
    "Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ygv1emO4Ki0"
   },
   "outputs": [],
   "source": [
    "import neuralcoref\n",
    "import spacy\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gc\n",
    "from Answer import Answer\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hle7707K7JBV"
   },
   "source": [
    "Setup everything for coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgAs3DSn7GKD"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "identifier='coref'\n",
    "last_check=0\n",
    "step_size=1000\n",
    "\n",
    "def load_pickles(identifier, checkpoint):\n",
    "  if os.path.exists(\"df\"+identifier+str(checkpoint)+\".pickle\"):\n",
    "    df = pd.read_pickle(\"df\"+identifier+str(checkpoint)+\".pickle\")\n",
    "  return df\n",
    "\n",
    "def dump_pickles(identifier, checkpoint, df):\n",
    "  df.to_pickle(\"df\"+identifier+str(checkpoint)+\".pickle\")\n",
    "  gc.collect()\n",
    "  return \n",
    "\n",
    "def make_corefs(content):\n",
    "    content=str(re.sub(\"\\.(?=\\s[a-z0-9]|\\sI[\\W\\s])\", \",\", content))\n",
    "    doc=nlp(content)\n",
    "    return doc._.coref_resolved\n",
    "\n",
    "df = pd.read_pickle(\"final_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdpMgaKm7RwM"
   },
   "source": [
    "Do coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKZijOCs7gQF"
   },
   "outputs": [],
   "source": [
    "for i in range(last_check+1,int(df.shape[0]/step_size)):\n",
    "  print(i)\n",
    "  for j in range(step_size):\n",
    "    df.iloc[step_size*(i-1)+j]['answer']=make_corefs(df.iloc[step_size*(i-1)+j]['answer'])\n",
    "  dump_pickles(identifier,i,df)\n",
    "print('done with ordered')\n",
    "for j in range(df.shape[0]-int(df.shape[0]/step_size)*step_size):\n",
    "  df.iloc[step_size*int(df.shape[0]/step_size)+j]['answer']=make_corefs(df.iloc[step_size*int(df.shape[0]/step_size)+j]['answer'])\n",
    "df.to_pickle(identifier+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcG4Kx3i89Ar"
   },
   "source": [
    "Setup for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NOPFTwb7vyD"
   },
   "outputs": [],
   "source": [
    "identifier=identifier\n",
    "last_check=1\n",
    "step_size=100\n",
    "#df is still from the cell above above\n",
    "\n",
    "def parse_entry(entry,verb_dict,verb_list):\n",
    "    result=dict()\n",
    "    result['question']=' '.join([token.text for token in utils.sp(entry['question'])])\n",
    "    phrase_corpus, triplet_id, parsed_text,parsed=Answer(entry['answer']).create_training(verb_dict,verb_list)\n",
    "    result['corpus']=' ; '.join(phrase_corpus)\n",
    "    result['tags']=' '.join(['<phrase>']*len(phrase_corpus))\n",
    "    result['triplet_id']=' ; '.join([re.sub('\\,','',str(x))[1:-1] for x in triplet_id])\n",
    "    result['parsed_text']=parsed_text\n",
    "    result['parsed']=' '.join([str(x) for x in parsed])\n",
    "    return result\n",
    "\n",
    "def load_pickles(identifier, checkpoint):\n",
    "  if os.path.exists(\"verb_dict\"+identifier+str(checkpoint)+\".pickle\"):\n",
    "    with open('verb_dict'+identifier+str(checkpoint)+'.pickle', 'rb') as handle:\n",
    "      verb_dict = pickle.load(handle)\n",
    "    with open('verb_list'+identifier+str(checkpoint)+'.pickle', 'rb') as handle:\n",
    "      verb_list = pickle.load(handle)\n",
    "    with open('result'+identifier+str(checkpoint)+'.pickle', 'rb') as handle:\n",
    "      result = pickle.load(handle)\n",
    "  else:\n",
    "    print('File does not exist yet.')\n",
    "    verb_dict=dict()\n",
    "    verb_list=[]\n",
    "    result=[]\n",
    "  return verb_dict, verb_list, result\n",
    "\n",
    "def dump_pickles(identifier, checkpoint, verb_dict, verb_list, result):\n",
    "  with open(\"verb_dict\"+identifier+str(checkpoint)+\".pickle\", 'wb') as handle:\n",
    "      pickle.dump(verb_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  with open(\"verb_list\"+identifier+str(checkpoint)+\".pickle\", 'wb') as handle:\n",
    "      pickle.dump(verb_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  with open(\"result\"+identifier+str(checkpoint)+\".pickle\", 'wb') as handle:\n",
    "      pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  return \n",
    "\n",
    "verb_dict, verb_list, result=load_pickles(identifier, last_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFSGYiCU9gat"
   },
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0om52TA9et4"
   },
   "outputs": [],
   "source": [
    "for i in range(last_check+1,int(df.shape[0]/step_size)):\n",
    "  print(i)\n",
    "  df[step_size*(i-1):step_size*i].apply(lambda x: result.append(parse_entry(x,verb_dict,verb_list)), axis=1)\n",
    "  dump_pickles(identifier,i,verb_dict,verb_list,result)\n",
    "print('done with ordered')\n",
    "df[step_size*i:].apply(lambda x: result.append(parse_entry(x,verb_dict,verb_list)), axis=1)\n",
    "dump_pickles(identifier,1+df.shape[0]/step_size,verb_dict,verb_list,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxmENzAm8Z5a"
   },
   "source": [
    "Post-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN-zxpPs8ZKk"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(result) \n",
    "df=df.sample(frac=1, random_state=36)\n",
    "df=df.dropna(axis=0, how='any')\n",
    "df=df[df.iloc[:,4].apply(lambda x: len(x)<1000)]\n",
    "df=df[df.iloc[:,1].apply(lambda x: len(x)<1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1wsMNkf8PHk"
   },
   "source": [
    "Write to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKhXCZ6r8OKG"
   },
   "outputs": [],
   "source": [
    "identifier='../GraphWriter-master/data/preprocessed'\n",
    "m=df.iloc[:50]\n",
    "m.to_csv(identifier+'.control.tsv', sep='\\t', index=False, header=False)\n",
    "m=df.iloc[50:1050]\n",
    "m.to_csv(identifier+'.val.tsv', sep='\\t', index=False, header=False)\n",
    "m=df.iloc[1050:2050]\n",
    "m.to_csv(identifier+'.test.tsv', sep='\\t', index=False, header=False)\n",
    "m=df.iloc[2050:]\n",
    "m.to_csv(identifier+'.train.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "with open(identifier+'.vocab', 'w') as filehandle:\n",
    "    filehandle.writelines(\"%s\\n\" % verb.upper() for verb in verb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hI-lDTb-thC"
   },
   "source": [
    "Train with GraphWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJEQ67DecD4R"
   },
   "outputs": [],
   "source": [
    "!python ../GraphWriter-master/train.py -save ../GraphWriter-master/partisanResponses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5zC3KRld2_YH"
   },
   "source": [
    "Use file with lowest vloss in the folder \"partisanResponses\" of GraphWriter-master to generate responses on test data.\n",
    "\n",
    "\n",
    "E.g. in the next cell \"9.vloss-3.980539.lr-0.1\" was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ek1BF81C7h1T"
   },
   "outputs": [],
   "source": [
    "!python ../GraphWriter-master/generator.py -save=../GraphWriter-master/partisanResponses/9.vloss-3.980539.lr-0.1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPUENBdua6BzddLc+SwHHh5",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GraphWriter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
